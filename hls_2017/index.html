<!DOCTYPE html>
<html>
  <head>
    <title>Bilingual research:</title>
    <meta charset="utf-8">
    <meta name="author" content="Joseph V. Casillas, PhD" />
    <link rel="stylesheet" href="../assets/css/mySlides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Bilingual research:
## Perception experiment with PsychoPy2
### Joseph V. Casillas, PhD
### Rutgers University </br> 10/26/2017

---










# Goals

### Provide an overview of PsychoPy2

- What is it? 
- How does it work?

### Why you should care

- Gain better understanding of psycholinguistic experiments

### What will you learn?

- You will be able to create your own simple experiment
- You will have the resources to create more complicated experiments

---

# Plan

- Overview of PsychoPy2
- Demo
- Using PsychoPy2 - the interface
- Creating a simple experiment - Stroop task
- Dealing with results
- Concluding ideas

---
class: inverse, middle, center

# Overview

---

# What is it?

- PsychoPy2 is a free program made in Python 
- It can be used to create experiments in psychology, psychophysics, neuroscience and linguistics.

&lt;/br&gt;

# Why do you want it?

- It's free!
- It's cross-platform
- It has a GUI (builder mode) or you can write in code

---

# What is it good for?

- PsychoPy2 can be used to create psycholinguistic tasks: 
    - 2AFC
    - AX, AXB, ABX
    - Lexical decision (masked prime)
    - even production experiments

&lt;/br&gt;

# What is it not good for?

- ?

---

# Getting started

### Download latest version of PsychoPy2

- http://sourceforge.net/projects/psychpy/files/PsychoPy/
- You can also google 'psychopy'
- Choose 'standalone' version

&lt;/br&gt;

### Download workshop files

- http://www.jvcasillas.com/teaching/psychopy/

---
class: inverse, middle, center

# Examples

---

# Risky business

.pull-left[

- Balloon Analogue Risk Task (BART) (Lejuez et al., 2002)
- The measure is designed to quantify individual differences in risk-taking.

]

.pull-right[

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/cruise.png"&gt;
&lt;/div&gt;

]

---

# Mental rotation

.pull-left[

- Cognitive task related to mental representations of objects (Gray &amp; Pasmanter, 2013)

&lt;/br&gt; 

&lt;div align="center"&gt;
  &lt;img src="../assets/img/graph.png"&gt;    
&lt;/div&gt;

]

.pull-right[

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/f.png"&gt;
  &lt;img src="../assets/img/fr.png"&gt;
&lt;/div&gt;

&lt;!-- - The time taken to decide if two images are the same or different depends linearly on the angle of rotation. So the longest time should be at 180 degress, and the expected
result is a peak-shape graph of RT as a function of rotation angle 
 --&gt;
]

---

# A linguistic experiment

.pull-left[

- 2AFC
- Interested in perception of non-native vowel contrasts
    - What acoustic cues do late-learners of English use to perceive tense/lax contrasts?
    - Spectrum? Duration?
- /i/-/ɪ/

]

.pull-right[

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/sheep1.png"&gt;  
  &lt;/br&gt;
  &lt;img src="../assets/img/ship1.png"&gt;
&lt;/div&gt;

]

---

# The stimuli

- 11-step spectrum continuum
- 11-step duration continuum

&lt;div align="center"&gt;
  &lt;img src="../assets/img/stimuli.png"&gt;
&lt;/div&gt;

---

# Results

&lt;div align="center"&gt;
  &lt;img src="../assets/img/ne.png"&gt;
  &lt;img src="../assets/img/ll.png"&gt;
&lt;/div&gt;

---
class: inverse, middle, center

# The interface

---

# The interface (Coder mode)

.pull-left[

```
import itertools

def iter_primes():
  # an iterator of all numbers between 2 and +infinity
  numbers = itertools.count(2)

  # generate primes forever
  while True:
  # get the first number from the iterator
    prime = numbers.next()
    yield prime
for p in iter_primes():
  if p &gt; 1000:
    break
  print p
```

]

.pull-right[

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/confundido.png"&gt;
&lt;/div&gt;

]

---

# The interface (Builder mode)

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/screeny.png"&gt;
&lt;/div&gt;

- Provides a graphical user interface
- Linear representation of experiment 'flow'
- Row view of routine components

---

# The interface (Experiment flow)

- The experiment advances linearly from left to right
- Each element (a routine) finishes before advancing
- Similar to slides in a power point

&lt;/br&gt;

&lt;div align="center"&gt;
  &lt;img src="../assets/img/flow.png"&gt;
&lt;/div&gt;

---

# Routines

- Individual view of each 'slide'
- Comprised of a series of components that perform a task

&lt;div align="center"&gt;
  &lt;img src="../assets/img/routines.png"&gt;
&lt;/div&gt;

---

# Components list

.pull-left[

- Stimuli
    - Text/Audio/Img/Video
- Responses
	- Keyboard, lykert scales, button boxes, mouse tracking, eye tracking, microphone
- Custom
	- Python code

]

.pull-right[

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/components.png"&gt;
&lt;/div&gt;

]

---
class: inverse, middle, center

# Demo

---

# How to build your own experiment

- Decide what you want to do
- Find a similar template
- Choose variables
- Create loops

---

# Stroop task

&lt;div align="center"&gt;
  &lt;img src="../assets/img/stroop.png"&gt;
&lt;/div&gt;

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2
    - Open new builder window 
    - Save new experiment as 'stroop.psyexp' in the 'stroop' folder
3. Select new keyboard response component


---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/kb_response1.png"&gt;
&lt;/div&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/kb_response2.png"&gt;
&lt;/div&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/step1.png"&gt;
&lt;/div&gt;

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. &lt;blue&gt;Select new text stimuli component&lt;/blue&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/text_response1.png"&gt;
&lt;/div&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/text_response2.png"&gt;
&lt;/div&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/step2.png"&gt;
&lt;/div&gt;

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. Select new text stimuli component
5. &lt;blue&gt;Create condition file&lt;/blue&gt;
    - Open excel (or text editor)
    - Create 'text' column
    - Create 'color' column
    - Create 'corrAns' column
    - Create 'congruent' column

---

&lt;/br&gt;

&lt;div align="center"&gt;
  &lt;img src="../assets/img/cf_excel1.png"&gt;
  &lt;img src="../assets/img/cf_texted1.png"&gt;
&lt;/div&gt;

---

&lt;/br&gt; 

&lt;div align="center"&gt;
  &lt;img src="../assets/img/cf_excel2.png"&gt;
  &lt;img src="../assets/img/cf_texted2.png"&gt;
&lt;/div&gt;

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. Select new text stimuli component
5. Create condition file
6. &lt;blue&gt;Save condition file in 'stroop' folder, create loop&lt;/blue&gt;

---

&lt;/br&gt;

&lt;div align="center"&gt;
  &lt;img src="../assets/img/loop1.png"&gt;
&lt;/div&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/loop2.png"&gt;
&lt;/div&gt;

---

&lt;div align="center"&gt;
  &lt;img src="../assets/img/loop3.png"&gt;
&lt;/div&gt;

---

# Stroop task

&lt;div style="float: right"&gt;
  &lt;img src="../assets/img/run.png"&gt;
&lt;/div&gt;

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. Select new text stimuli component
5. Create condition file
6. Save condition file in 'stroop' folder, create loop
7. &lt;blue&gt;Run experiment&lt;/blue&gt;

--

- You made an awesome experiment, collected data... now what?

---

# Dealing with results

- Specify the output format
- Import results directly into stats program


```r
# Combine files vertically into large data frame
temp &lt;- list.files(path = "../demos/3_stroop/data", 
    full.names = TRUE, pattern = ".csv")
myfiles &lt;- lapply(temp, read.csv,sep = ",")
df &lt;- do.call("rbind",myfiles)
```

---

# Plots

&lt;img src="index_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

# Plots

&lt;img src="index_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---

# Statistics


```r
lm(log10(resp.rt) ~ participant, data = df)
```

&lt;!-- html table generated in R 3.4.0 by xtable 1.8-2 package --&gt;
&lt;!-- Tue Aug 22 14:11:34 2017 --&gt;
&lt;table border=1&gt;
&lt;tr&gt; &lt;th&gt;  &lt;/th&gt; &lt;th&gt; Estimate &lt;/th&gt; &lt;th&gt; Std. Error &lt;/th&gt; &lt;th&gt; t value &lt;/th&gt; &lt;th&gt; Pr(&amp;gt;|t|) &lt;/th&gt;  &lt;/tr&gt;
  &lt;tr&gt; &lt;td align="right"&gt; (Intercept) &lt;/td&gt; &lt;td align="right"&gt; 0.0683 &lt;/td&gt; &lt;td align="right"&gt; 0.0245 &lt;/td&gt; &lt;td align="right"&gt; 2.79 &lt;/td&gt; &lt;td align="right"&gt; 0.0057 &lt;/td&gt; &lt;/tr&gt;
  &lt;tr&gt; &lt;td align="right"&gt; participant &lt;/td&gt; &lt;td align="right"&gt; -0.0288 &lt;/td&gt; &lt;td align="right"&gt; 0.0039 &lt;/td&gt; &lt;td align="right"&gt; -7.30 &lt;/td&gt; &lt;td align="right"&gt; 0.0000 &lt;/td&gt; &lt;/tr&gt;
   &lt;/table&gt;

---

# Conclusion

- You now know the basics of Pyschopy2
	- Can be used to create simple psycholinguistic experiments
	- Provided templates can be modified to create more complex experiments

&lt;/br&gt;

&lt;div align="center"&gt;
  &lt;img width="400" src="../assets/img/clap.gif"&gt;
&lt;/div&gt;

---

# Conclusion

### Pros

- Free
- Allows for control over everything
- Easy to streamline into research workflow

### Cons

- Complicated?
- Ugly?

---

# More resources

- http://www.jvcasillas.com/teaching/psychopy/
- http://www.psychopy.org/ 
- http://code.google.com/p/psychopy/ 
- http://www.youtube.com/watch?v=VV6qhuQgsiI

---

# References

- &lt;font size="5"&gt;Gray, J. &amp; Pasmanter, N. (2013). [github][github]&lt;/font&gt;
- &lt;font size="5"&gt;Lejuez, C. W., Aklin, W. M., Zvolensky, M. J., &amp; Pedulla, C. M. (2003). Evaluation of the Balloon Analogue Risk Task (BART) as a predictor of adolescent real-world risk-taking behaviours. Journal of adolescence, 26(4), 475-479. &lt;/font&gt;
- &lt;font size="5"&gt;McGuire, G. (2010, in progress) A Brief Primer on Experimental Designs in Speech Perception Research. http://people.ucsc.edu/~gmcguir1/ &lt;/font&gt;
- &lt;font size="5"&gt;Simonet, M. (2012). El diseño de experimentos para el estudio de la percepción del habla. *Laboratory Approaches to Romance Phonology Conference*. El Colegio de México, México D.F.&lt;/font&gt;


[github]: https://github.com/psychopy/psychopy/tree/master/psychopy/demos/builder/mental_rotation
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {window.dispatchEvent(new Event('resize'));});
(function() {var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler"); if (!r) return; s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }"; d.head.appendChild(s);})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
