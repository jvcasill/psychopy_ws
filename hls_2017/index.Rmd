---
title: "Best practices and tools for pycholinguistic research with bilinguals:"
subtitle: "A gentle introduction to PsychoPy2"
author: "Joseph V. Casillas, PhD | Rutgers University"
date: "Hispanic Linguistics Symposium - Lubbock, TX </br> 10/26/2017"
output:
  xaringan::moon_reader:
    lib_dir: assets
    css: "http://www.jvcasillas.com/ru_xaringan_css/css/ru_xaringan.css"
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    includes:
      in_header: "../assets/partials/header.html"
---



```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r eval=FALSE, echo=FALSE}
rmarkdown::render("./hls_2017/index.Rmd")
xaringan::inf_mr()
```

class: inverse, middle

.center[

# **Don't miss out...**

]

.pull-left[

- <white>These slides and all materiales are available on github</white>

- <white>Write down contact information in case you have to leave early</white>

]

.pull-right[

<a href="mailto:joseph.casillas@rutgers.edu"><white><i class="fa fa-paper-plane fa-fw"></i></white>&nbsp; <white>joseph.casillas@rutgers.edu</a></white><br>
<a href="https:www.jvcasillas.com"><white><i class="fa fa-link fa-fw"></i></white>&nbsp; <white>jvcasillas.com</a></white><br>
<a href="http://twitter.com/jvcasill"><white><i class="fa fa-twitter fa-fw"></i></white>&nbsp; <white>@jvcasill</a></white><br>
<a href="http://github.com/jvcasillas"><white><i class="fa fa-github fa-fw"></i></white>&nbsp; <white>@jvcasillas</a></white><br>

]

---
background-image: url(http://blueforeststudios.com/azultree/wp-content/uploads/2015/11/Real-time-marketing.jpg)
background-size: 600px
background-position: 100% 50%

# What are we doing?

### Part I - Best practices

- Bilingual language modes
- Language proficiency
- Language dominance

--

### Part II - PsychoPy2

- What is psychopy and why do you want it?
- Where and how do you get it?
- What is psychopy good for?
- What is psychopy not good for?
- Demo: stroop task
- Bonus:
  - integration with R, project management
  - OSF, templates and reproducible research

---
class: inverse, middle, center

# Part I

### Best practices for pycholinguistic research with bilinguals

---
background-image: url(../assets/img/modes.png)
background-size: 300pt
background-position: 20% 50%
background-color: black
class: right

# Bilingual language modes

---

# Bilingual language modes

### The basics

- What are they?
- Why are they important to me?
- What do I need to know/do?

---
background-image: url(../assets/img/proficiency.png)
background-size: 350pt
background-position: 20% 105%
background-color: black
class: right

# Language proficiency

### ...and how to measure it

---

# Language proficiency

### The basics

- What is it?
- Why do I care?
- What do I need to know/do?

### Options

- LexTALE
- DELE

---
background-color: black
class: right

# Language dominance 

### ...and how to measure it

---

# Language dominance

### The basics

- What is it?
- Why is it important to me?
- What do I need to know/do?

### Options

- BLP
- Multi-Lingual Naming Test MINT

---






























class: inverse, middle, center

# Part II

## Introduction to PsychoPy2

---
class: inverse, center

# How to...

## 1. **Just watch**

---
class: inverse, center

# How to...

## 2. **Follow along with me**

---
class: inverse, middle, center

# You should have PsychoPy2 installed 
--

# If not, get it here: https://github.com/psychopy/psychopy/releases

--

### ...**but hurry!**

---

# Goals

### Provide an overview of PsychoPy2

- What is it? 
- How does it work?

### Why you should care

- Gain better understanding of psycholinguistic experiments

### What will you learn?

- You will be able to create your own simple experiment
- You will have the resources to create more complicated experiments

---

# Plan

- Overview of PsychoPy2
- Demo
- Using PsychoPy2 - the interface
- Creating a simple experiment - Stroop task
- Dealing with results
- Concluding ideas

---
class: inverse, middle, center

# Overview

---

# Overview

### What is it?

- PsychoPy2 is a free program made in Python 
- It can be used to create experiments in psychology, psychophysics, neuroscience and linguistics.

</br>

### Why do you want it?

- It's free!
- It's cross-platform
- It has a GUI (builder mode) or you can write in code

---

# Overview

### What is it good for?

- PsychoPy2 can be used to create psycholinguistic tasks: 
    - 2AFC
    - AX, AXB, ABX
    - Lexical decision (masked prime)
    - even production experiments

</br>

### What is it not good for?

- ?

---

# Getting started

### Download latest version of PsychoPy2

- http://sourceforge.net/projects/psychpy/files/PsychoPy/
- You can also google 'psychopy'
- Choose 'standalone' version

</br>

### Download workshop files

- http://www.jvcasillas.com/teaching/psychopy/

---
class: inverse, middle, center

# Examples

---

# Risky business

.pull-left[

- Balloon Analogue Risk Task (BART) (Lejuez et al., 2002)
- The measure is designed to quantify individual differences in risk-taking.

]

.pull-right[

<div style="float: right">
  <img src="../assets/img/cruise.png">
</div>

]

---

# Mental rotation

.pull-left[

- Cognitive task related to mental representations of objects (Gray & Pasmanter, 2013)

</br> 

<div align="center">
  <img src="../assets/img/graph.png">    
</div>

]

.pull-right[

<div style="float: right">
  <img src="../assets/img/f.png">
  <img src="../assets/img/fr.png">
</div>

<!-- - The time taken to decide if two images are the same or different depends linearly on the angle of rotation. So the longest time should be at 180 degress, and the expected
result is a peak-shape graph of RT as a function of rotation angle 
 -->
]

---

# A linguistic experiment

.pull-left[

- 2AFC
- Interested in perception of non-native vowel contrasts
    - What acoustic cues do late-learners of English use to perceive tense/lax contrasts?
    - Spectrum? Duration?
- /i/-/ɪ/

]

.pull-right[

<div style="float: right">
  <img src="../assets/img/sheep1.png">  
  </br>
  <img src="../assets/img/ship1.png">
</div>

]

---

# The stimuli

- 11-step spectrum continuum
- 11-step duration continuum

<div align="center">
  <img src="../assets/img/stimuli.png">
</div>

---

# Results

<div align="center">
  <img src="../assets/img/ne.png">
  <img src="../assets/img/ll.png">
</div>

---
class: inverse, middle, center

# The interface

---

# The interface (Coder mode)

.pull-left[

```
import itertools

def iter_primes():
  # an iterator of all numbers between 2 and +infinity
  numbers = itertools.count(2)

  # generate primes forever
  while True:
  # get the first number from the iterator
    prime = numbers.next()
    yield prime
for p in iter_primes():
  if p > 1000:
    break
  print p
```

]

.pull-right[

<div style="float: right">
  <img src="../assets/img/confundido.png">
</div>

]

---

# The interface (Builder mode)

<div style="float: right">
  <img src="../assets/img/screeny.png">
</div>

- Provides a graphical user interface
- Linear representation of experiment 'flow'
- Row view of routine components

---

# The interface (Experiment flow)

- The experiment advances linearly from left to right
- Each element (a routine) finishes before advancing
- Similar to slides in a power point

</br>

<div align="center">
  <img src="../assets/img/flow.png">
</div>

---

# Routines

- Individual view of each 'slide'
- Comprised of a series of components that perform a task

<div align="center">
  <img src="../assets/img/routines.png">
</div>

---

# Components list

.pull-left[

- Stimuli
    - Text/Audio/Img/Video
- Responses
	- Keyboard, lykert scales, button boxes, mouse tracking, eye tracking, microphone
- Custom
	- Python code

]

.pull-right[

<div style="float: right">
  <img src="../assets/img/components.png">
</div>

]

---
class: inverse, middle, center

# Demo

---

# How to build your own experiment

- Decide what you want to do
- Find a similar template
- Choose variables
- Create loops

---

# Stroop task

<div align="center">
  <img src="../assets/img/stroop.png">
</div>

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2
    - Open new builder window 
    - Save new experiment as 'stroop.psyexp' in the 'stroop' folder
3. Select new keyboard response component


---

<div align="center">
  <img src="../assets/img/kb_response1.png">
</div>

---

<div align="center">
  <img src="../assets/img/kb_response2.png">
</div>

---

<div align="center">
  <img src="../assets/img/step1.png">
</div>

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. <blue>Select new text stimuli component</blue>

---

<div align="center">
  <img src="../assets/img/text_response1.png">
</div>

---

<div align="center">
  <img src="../assets/img/text_response2.png">
</div>

---

<div align="center">
  <img src="../assets/img/step2.png">
</div>

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. Select new text stimuli component
5. <blue>Create condition file</blue>
    - Open excel (or text editor)
    - Create 'text' column
    - Create 'color' column
    - Create 'corrAns' column
    - Create 'congruent' column

---

</br>

<div align="center">
  <img src="../assets/img/cf_excel1.png">
  <img src="../assets/img/cf_texted1.png">
</div>

---

</br> 

<div align="center">
  <img src="../assets/img/cf_excel2.png">
  <img src="../assets/img/cf_texted2.png">
</div>

---

# Stroop task

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. Select new text stimuli component
5. Create condition file
6. <blue>Save condition file in 'stroop' folder, create loop</blue>

---

</br>

<div align="center">
  <img src="../assets/img/loop1.png">
</div>

---

<div align="center">
  <img src="../assets/img/loop2.png">
</div>

---

<div align="center">
  <img src="../assets/img/loop3.png">
</div>

---

# Stroop task

<div style="float: right">
  <img src="../assets/img/run.png">
</div>

1. Create a new folder 'stroop' on your desktop
2. Launch Pyschopy2/Open new builder window
3. Select new keyboard response component
4. Select new text stimuli component
5. Create condition file
6. Save condition file in 'stroop' folder, create loop
7. <blue>Run experiment</blue>

--

- You made an awesome experiment, collected data... now what?

---

# Dealing with results

- Specify the output format
- Import results directly into stats program

```{r}
# Combine files vertically into large data frame
temp <- list.files(path = "../demos/3_stroop/data", 
    full.names = TRUE, pattern = ".csv")
myfiles <- lapply(temp, read.csv,sep = ",")
df <- do.call("rbind",myfiles)
```

---

# Plots

```{r, echo=FALSE, fig.align='center', fig.width=11, fig.height=6, fig.retina=2}
# plot rt as a function of text
par(mfrow=c(1,2))
# get descriptive statistics of subsets of factors
prop <- aggregate(resp.corr ~ letterColor, data = df, FUN = mean)
p <- with(prop, barplot(resp.corr, ylim = c(0,1), ylab = "Proportion of correct responses", xlab = "Colors",
    col=c("red","green", "blue")))
axis(1, at=p, labels=prop$letterColor)
with(df, plot(log(resp.rt)~letterColor, ylab = "log(RT)", xlab = "Colors", 
    col=c("red","green", "blue")))
```

---

# Plots

```{r, echo=FALSE, fig.align='center', fig.width=11, fig.retina=2}
par(mfrow=c(1,1))
mod2 <- lm(log10(resp.rt) ~ participant, data = df)
with(df, plot(participant, log10(resp.rt), ylab = "log10(RT)", xlab = "Trials", 
    col = rgb(0, 0, 204, 102, maxColorValue = 255), main = "Reaction time as a function of trial"))
axis(1, at=c(1:10))
abline(mod2, col = "red")
```

---

# Statistics

```{r, echo=TRUE, eval=FALSE}
lm(log10(resp.rt) ~ participant, data = df)
```

```{r, echo=FALSE, results='asis', message = FALSE}
library(stargazer); library(xtable)
#stargazer(mod2, type = 'html', align = FALSE, no.space=TRUE, 
#    single.row=TRUE, omit.stat=c("LL","ser", "rsq"))
print(xtable(mod2), type = 'html')
```

---

# Conclusion

- You now know the basics of Pyschopy2
	- Can be used to create simple psycholinguistic experiments
	- Provided templates can be modified to create more complex experiments

</br>

<div align="center">
  <img width="400" src="../assets/img/clap.gif">
</div>

---

# Conclusion

### Pros

- Free
- Allows for control over everything
- Easy to streamline into research workflow

### Cons

- Complicated?
- Ugly?

---

# More resources

- http://www.jvcasillas.com/teaching/psychopy/
- http://www.psychopy.org/ 
- http://code.google.com/p/psychopy/ 
- http://www.youtube.com/watch?v=VV6qhuQgsiI

---

# References

- <font size="5">Gray, J. & Pasmanter, N. (2013). [github][github]</font>
- <font size="5">Lejuez, C. W., Aklin, W. M., Zvolensky, M. J., & Pedulla, C. M. (2003). Evaluation of the Balloon Analogue Risk Task (BART) as a predictor of adolescent real-world risk-taking behaviours. Journal of adolescence, 26(4), 475-479. </font>
- <font size="5">McGuire, G. (2010, in progress) A Brief Primer on Experimental Designs in Speech Perception Research. http://people.ucsc.edu/~gmcguir1/ </font>
- <font size="5">Simonet, M. (2012). El diseño de experimentos para el estudio de la percepción del habla. *Laboratory Approaches to Romance Phonology Conference*. El Colegio de México, México D.F.</font>


[github]: https://github.com/psychopy/psychopy/tree/master/psychopy/demos/builder/mental_rotation





